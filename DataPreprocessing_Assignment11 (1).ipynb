{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IUjqX9hqbb-6"
   },
   "outputs": [],
   "source": [
    "#Data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AketbKR7cAaF"
   },
   "source": [
    "**Step 1: Importing the libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_ApieS21bdbN"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq1_kSwHcH4n"
   },
   "source": [
    "**Step 2: Importing dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HefV9KfcbdoE"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxaiAQCQcX7Z"
   },
   "source": [
    "**Step 3: Handling the missing data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "veMJJywXbdr-"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, 3].values\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean') \n",
    "imputer=imputer.fit(X[:,1:3])\n",
    "X[:,1:3]=imputer.transform(X[:,1:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wBdj7QVmciFh"
   },
   "source": [
    "**Step 4: Encoding categorical data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "Nbgm4YJBbdwG"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "labelencoder_X=LabelEncoder()\n",
    "X[:,0]=labelencoder_X.fit_transform(X[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cFSk6n3XcpIs"
   },
   "source": [
    "**Step 5: Creating a dummy variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "9ETxfCgZbd0O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1.0' '0.0' '0.0' '44.0' '72000.0']\n",
      " ['0.0' '0.0' '1.0' '27.0' '48000.0']\n",
      " ['0.0' '1.0' '0.0' '30.0' '54000.0']\n",
      " ['0.0' '0.0' '1.0' '38.0' '61000.0']\n",
      " ['0.0' '1.0' '0.0' '40.0' '63777.77777777778']\n",
      " ['1.0' '0.0' '0.0' '35.0' '58000.0']\n",
      " ['0.0' '0.0' '1.0' '38.77777777777778' '52000.0']\n",
      " ['1.0' '0.0' '0.0' '48.0' '79000.0']\n",
      " ['0.0' '1.0' '0.0' '50.0' '83000.0']\n",
      " ['1.0' '0.0' '0.0' '37.0' '67000.0']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Astro\\AppData\\Local\\Temp/ipykernel_15344/2822231436.py:5: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X = np.array(columnTransformer.fit_transform(X), dtype = np.str)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "columnTransformer = ColumnTransformer([('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
    "\n",
    "X = np.array(columnTransformer.fit_transform(X), dtype = np.str)\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSSKm1p4c2md"
   },
   "source": [
    "**Step 6: Splitting the datasets into training sets and Test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "kw21hHAqbd4x"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YA8VCdb5c9Dh"
   },
   "source": [
    "**Step 7: Feature Scaling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "LhV2lO1Gbd9l"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zRwvGcTdbeCd"
   },
   "outputs": [],
   "source": [
    "sc_X=StandardScaler()\n",
    "X_train=sc_X.fit_transform(X_train)\n",
    "X_test=sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 1.00000000e+00 2.77555756e-17 3.00000000e+01\n",
      "  5.40000000e+04]\n",
      " [0.00000000e+00 1.00000000e+00 2.77555756e-17 5.00000000e+01\n",
      "  8.30000000e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DataPreprocessing_Assignment11.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
